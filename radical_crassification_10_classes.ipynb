{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.0.0\n",
      "torchvision version: 0.2.1\n",
      "Is GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('torchvision version:', torchvision.__version__)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('Is GPU available:', use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体的な設定\n",
    "\n",
    "# デバイス\n",
    "device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "\n",
    "# バッチサイズ（もう少し大きくしたいがメモリの都合）\n",
    "batchsize = 64\n",
    "\n",
    "# シード値の指定（cuDNNによるランダム性はこれでも残るらしい）\n",
    "# seed = 1\n",
    "# torch.manual_seed(seed)\n",
    "# if use_gpu:\n",
    "#    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '../../data/'\n",
    "# 訓練画像が入っているディレクトリ（kmnistの漢字データからkanjivgのkanji2radicalにkeyとしてないものを除いた）\n",
    "image_dir = root_dir + 'kkanji2_expansion_can_get_radical/'\n",
    "# ログと重みを保存するためのディレクトリ\n",
    "save_dir = root_dir + 'kkanji2_result/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "# ラベルのためのjsonを読み込む\n",
    "with open(root_dir + 'kanjivg_radical/utf16_to_radical.json') as f:\n",
    "    utf16_to_radical = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root_dir + 'kanjivg_radical/kanji2radical.json') as f:\n",
    "    kanji_to_radical = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of radical: 10\n"
     ]
    }
   ],
   "source": [
    "# ラベルをone-hotで構築するために部首 -> one-hotの対応部分のインデックス　の辞書を作る\n",
    "# radical_set = set()\n",
    "# for value in utf16_to_radical.values():\n",
    "#    for v in value:\n",
    "#        radical_set.add(v)\n",
    "# 部首の非重複集合を作成し、リスト化してソート（恐らくutf-16順でソートされる（とにかく順番が一意ならよい））\n",
    "# radical_list = sorted(list(radical_set))\n",
    "\n",
    "# 上で述べた通りの辞書を作成\n",
    "# radical_dict = {}\n",
    "# for index, radical in enumerate(radical_list):\n",
    "#    radical_dict[radical] = index\n",
    "\n",
    "# kanji2radicalのjsonファイルに存在する部首の種類の総数であり、学習するCNNの出力ノードの数\n",
    "\n",
    "valid_labels = {'氵':0, '亻':1, '扌':2, '木':3, '糸':4, '言':5, '口':6, '⻌':7, '土':8, '心':9}\n",
    "n_radical = 10\n",
    "print('the number of radical:', n_radical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベルの構築及び学習画像とまとめるためのデータセットクラスを作成\n",
    "# one-hotラベルを呼び出しのたびにで作成するのは極めて非効率なのでちょっとなんとかしたい\n",
    "class KanjiRadicalDataset(Dataset):\n",
    "    def __init__(self, image_dir, image_name_list, utf16_to_radical, radical_dict, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_name_list = sorted(image_name_list)\n",
    "        \n",
    "        self.utf16_to_radical = utf16_to_radical\n",
    "        self.radical_dict = radical_dict\n",
    "        \n",
    "        self.n_radical = len(radical_dict)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_name_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_name_list[idx]        \n",
    "        image = Image.open(self.image_dir + image_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # ここが非効率、要改善\n",
    "        label = torch.zeros(self.n_radical+1)\n",
    "        utf16_code = image_name[:4]\n",
    "        radical_list = self.utf16_to_radical[utf16_code]\n",
    "        for radical in radical_list:\n",
    "            if radical in self.radical_dict.keys():\n",
    "                label[self.radical_dict[radical]] = 1\n",
    "            else:\n",
    "                label[self.n_radical] = 1\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training data: 94127\n",
      "The number of validation data: 23532\n"
     ]
    }
   ],
   "source": [
    "# train_test_splitで分割（高速化のためフォルダ内のファイルの名前を分割している）\n",
    "train_name_list, validation_name_list = train_test_split(os.listdir(image_dir), test_size = 0.2, random_state = seed)\n",
    "\n",
    "# data augmentationとして周囲8マスをゼロパディングしてそこから64x64をランダムクロップしている（data augmentationは今ここだけ）\n",
    "# ToTensor()で0~1の範囲に収めて、そこからNormalize()で-1~1の範囲にしているが、このNormalize()に渡す値は0.5ではよくない気がする\n",
    "tf_train = transforms.Compose([transforms.RandomCrop(64, padding=8), \\\n",
    "                               transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "# validationではランダムクロップはしない\n",
    "tf_validation = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_data = KanjiRadicalDataset(image_dir, train_name_list, \\\n",
    "                                 utf16_to_radical, valid_labels, transform=tf_train)\n",
    "validation_data = KanjiRadicalDataset(image_dir, validation_name_list, \\\n",
    "                                      utf16_to_radical, valid_labels, transform=tf_validation)\n",
    "\n",
    "print('The number of training data:', len(train_data))\n",
    "print('The number of validation data:', len(validation_data))\n",
    "\n",
    "# make DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True, num_workers=4)\n",
    "validation_loader = DataLoader(validation_data, batch_size=batchsize, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのラベルの分布を見る(重いのでコメントアウト)\n",
    "# radical_count = torch.zeros(n_radical)\n",
    "# for index, (image, label) in enumerate(validation_loader):\n",
    "#    radical_count += torch.sum(label, dim=0)\n",
    "#    print('\\rprogress[%d/%d]' % (index+1, len(validation_loader)), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radical_count_non_zero = radical_count[radical_count > 0]\n",
    "# plt.xlim([0,500])\n",
    "# plt.ylim([0,100])\n",
    "# plt.hist(radical_count_non_zero, bins = 100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(range(len(radical_count_non_zero)), radical_count_non_zero)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/preact_resnet.pyより PreActResNet-18\n",
    "# 一番最初の入力チャネルを1チャネルに変更、フィルタ数を全体的に増やしてある(4倍)\n",
    "# 本当は多分初期化（Heの初期化など？）をちゃんとやったほうが良いが、取り敢えずはこのまま\n",
    "# preactResNet-18の採用理由はkmnistの提案論文のbaselineに合わせるためだが、あれは32x32のkmnist, k49で使われたものなので、\n",
    "# 64x64のkkanjiにそのまま適用するのは微妙かも\n",
    "# データセットの提案論文ではmanifold mixupをdata augumentationとして採用しているが、取り敢えずはまだやっていない\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "    \n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        planes = 256 # ここを調整して全体のフィルタ数を変える\n",
    "        self.in_planes = planes\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block,   planes, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 2*planes, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 4*planes, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 8*planes, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(8*planes*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 8) # global average poolingなのでここの数は元々から変えてある\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def PreActResNet18(num_classes):\n",
    "    return PreActResNet(PreActBlock, [2,2,2,2], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of trainable parameters: 178572043\n",
      "\n",
      "Model:\n",
      " PreActResNet(\n",
      "  (conv1): Conv2d(1, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): PreActBlock(\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(1024, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (1): PreActBlock(\n",
      "      (bn1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv1): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=2048, out_features=11, bias=True)\n",
      ")\n",
      "\n",
      "Loss function:\n",
      " BCEWithLogitsLoss()\n",
      "\n",
      "Optimizer:\n",
      " SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.1\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0005\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = PreActResNet18(n_radical+1)\n",
    "net = net.to(device)\n",
    "\n",
    "# ロスはbinary_cross_entropy with logits(第1引数にsigmoidをかけてbinary cross entropy)\n",
    "# NNのモデルの出力層にsigmoidをかけるより数値計算上の安定性に優れるらしい\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# この辺の設定は上述のPreActResnet-18の参考にしたリポジトリと同じ\n",
    "# 学習率は適宜手動調節すること\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "# 学習可能なパラメータの数\n",
    "num_trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "\n",
    "print('The number of trainable parameters:', num_trainable_params)\n",
    "print('\\nModel:\\n', net)\n",
    "print('\\nLoss function:\\n', criterion)\n",
    "print('\\nOptimizer:\\n', optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ある漢字について、その漢字の部首を全て正解した時に「正解」と定義して漢字ごとの平均accuracyと、\n",
    "# 部首ごとのaccuracyを返したいけどこれは部首ごとのaccuracyになっていない気がする\n",
    "def calculate_accuracy_per_kanji_and_radical(outputs, labels):\n",
    "    with torch.no_grad():\n",
    "        outputs = torch.sigmoid(outputs) > 0.5\n",
    "        labels = labels.type(torch.uint8)\n",
    "        is_correct = (outputs == labels)\n",
    "        accuracy_per_kanji = (torch.sum(is_correct, dim=1) == outputs.size(1)).float().mean()\n",
    "        accuracy_per_radical = is_correct.float().mean()\n",
    "    return [accuracy_per_kanji, accuracy_per_radical]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1epoch分の訓練\n",
    "def train(train_loader):\n",
    "    net.train()\n",
    "    running_loss = 0\n",
    "    running_accuracy_per_kanji = 0\n",
    "    running_accuracy_per_radical = 0\n",
    "    \n",
    "    for batch_index, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        accuracies = calculate_accuracy_per_kanji_and_radical(outputs.detach(), labels)\n",
    "        running_accuracy_per_kanji += accuracies[0]\n",
    "        running_accuracy_per_radical += accuracies[1]\n",
    "        \n",
    "        print('\\rtraining batch[%4d/%4d]' % (batch_index+1, len(train_loader)), end='')\n",
    "        \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    accuracy_per_kanji = running_accuracy_per_kanji / len(train_loader)\n",
    "    accuracy_per_radical = running_accuracy_per_radical / len(train_loader)\n",
    "    \n",
    "    return train_loss, accuracy_per_kanji, accuracy_per_radical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1epoch分のvalidation\n",
    "def validation(validation_loader):\n",
    "    net.eval()\n",
    "    running_loss = 0\n",
    "    running_accuracy_per_kanji = 0\n",
    "    running_accuracy_per_radical = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_index, (inputs, labels) in enumerate(validation_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            accuracies = calculate_accuracy_per_kanji_and_radical(outputs.detach(), labels)\n",
    "            running_accuracy_per_kanji += accuracies[0]\n",
    "            running_accuracy_per_radical += accuracies[1]            \n",
    "            \n",
    "            print('\\rvalidation batch[%4d/%4d]' % (batch_index+1, len(validation_loader)), end='')\n",
    "            \n",
    "    validation_loss = running_loss / len(validation_loader)\n",
    "    accuracy_per_kanji = running_accuracy_per_kanji / len(validation_loader)\n",
    "    accuracy_per_radical = running_accuracy_per_radical / len(validation_loader)\n",
    "    \n",
    "    return validation_loss, accuracy_per_kanji, accuracy_per_radical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 10.91 GiB total capacity; 9.65 GiB already allocated; 171.62 MiB free; 172.90 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-fc854f3e30c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy_per_kanji\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy_per_radical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mvalidation_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_accuracy_per_kanji\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_accuracy_per_radical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-4fa918bca249>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-30c2d67deebc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-30c2d67deebc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shortcut'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 10.91 GiB total capacity; 9.65 GiB already allocated; 171.62 MiB free; 172.90 MiB cached)"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "train_accuracy_per_kanji_list = []\n",
    "train_accuracy_per_radical_list = []\n",
    "\n",
    "validation_loss_list = []\n",
    "validation_accuracy_per_kanji_list = []\n",
    "validation_accuracy_per_radical_list = []\n",
    "\n",
    "n_epochs = 15\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss, train_accuracy_per_kanji, train_accuracy_per_radical = train(train_loader)\n",
    "    validation_loss, validation_accuracy_per_kanji, validation_accuracy_per_radical = validation(validation_loader)\n",
    "    \n",
    "    train_loss_list.append(train_loss)\n",
    "    train_accuracy_per_kanji_list.append(train_accuracy_per_kanji)\n",
    "    train_accuracy_per_radical_list.append(train_accuracy_per_radical)\n",
    "    \n",
    "    validation_loss_list.append(validation_loss)\n",
    "    validation_accuracy_per_kanji_list.append(validation_accuracy_per_kanji)\n",
    "    validation_accuracy_per_radical_list.append(validation_accuracy_per_radical)\n",
    "    \n",
    "    print('')\n",
    "    print('epoch[%3d/%3d] train[loss:%1.6f accuracy_per_kanji:%1.4f accuracy_per_radical:%1.4f]' \\\n",
    "          % (epoch+1, n_epochs, train_loss, train_accuracy_per_kanji, train_accuracy_per_radical), \\\n",
    "          '\\n          validation[loss:%1.6f accuracy_per_kanji:%1.4f accuracy_per_radical:%1.4f]'\n",
    "          % (validation_loss, validation_accuracy_per_kanji, validation_accuracy_per_radical))\n",
    "    \n",
    "    if epoch % 5 == 0 and epoch > 0:\n",
    "        torch.save(net.state_dict(), save_dir + 'weights_epoch_%d.pth' % (epoch+1))\n",
    "        torch.save(optimizer.state_dict(), save_dir + 'optimizer_epoch_%d.pth' % (epoch+1))\n",
    "        optimizer.param_groups[0]['lr'] *= 0.1\n",
    "    \n",
    "np.save(save_dir + 'train_loss_list.npy', np.array(train_loss_list))\n",
    "np.save(save_dir + 'train_accuracy_per_kanji_list.npy', np.array(train_accuracy_per_kanji_list))\n",
    "np.save(save_dir + 'train_accuracy_per_radical_list.npy', np.array(train_accuracy_per_radical_list))\n",
    "\n",
    "np.save(save_dir + 'validation_loss_list.npy', np.array(validation_loss_list))\n",
    "np.save(save_dir + 'validation_accuracy_per_kanji_list.npy', np.array(validation_accuracy_per_kanji_list))\n",
    "np.save(save_dir + 'validation_accuracy_per_radical_list.npy', np.array(validation_accuracy_per_radical_list))\n",
    "\n",
    "torch.save(net.state_dict(), save_dir + 'weights_final.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss_list)\n",
    "plt.plot(validation_loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy_per_radical_list)\n",
    "plt.plot(validation_accuracy_per_radical_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "亻\n",
      "尹\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffab3de93c8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_loader = DataLoader(validation_data, batch_size=batchsize, shuffle=True, num_workers=4)\n",
    "images, labels =  iter(test_loader).next()\n",
    "\n",
    "plt.imshow(images[0].view(64,64).numpy() * 0.5 + 0.5, cmap='gray')\n",
    "for index, label in enumerate(labels[0]):\n",
    "    if label == 1:\n",
    "        print(radical_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 236\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at /pytorch/aten/src/TH/THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-f3da2240b196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradical_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-30c2d67deebc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-30c2d67deebc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mshortcut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shortcut'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mshortcut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 0GB. Buy new RAM! at /pytorch/aten/src/TH/THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "outputs = net(images).cpu()\n",
    "for index, output in enumerate(outputs[0]):\n",
    "    if output == 1:\n",
    "        print(radical_list[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
