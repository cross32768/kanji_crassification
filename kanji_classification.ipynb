{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.0.0\n",
      "torchvision version: 0.2.1\n",
      "Is GPU available: True\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('torchvision version:', torchvision.__version__)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('Is GPU available:', use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general settings\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if use_gpu else 'cpu')\n",
    "\n",
    "# batchsize\n",
    "batchsize = 128\n",
    "\n",
    "# seed setting (warning : cuDNN's randomness is remaining)\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "if use_gpu:\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory settings\n",
    "root_dir = '../../data/'\n",
    "# directory for training data images\n",
    "image_dir = root_dir + 'kkanji2_expansion_can_get_radical/'\n",
    "# directory for save logs and trained weights\n",
    "save_dir = root_dir + 'kkanji2_result'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)\n",
    "\n",
    "# load json for label\n",
    "with open(root_dir + 'kanjivg_radical/utf16_to_radical.json') as f:\n",
    "    utf16_to_radical = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of radical: 1300\n"
     ]
    }
   ],
   "source": [
    "# prepare dict for one-hot encoding\n",
    "radical_set = set()\n",
    "for value in utf16_to_radical.values():\n",
    "    for v in value:\n",
    "        radical_set.add(v)\n",
    "radical_list = sorted(list(radical_set))\n",
    "\n",
    "radical_dict = {}\n",
    "for index, radical in enumerate(radical_list):\n",
    "    radical_dict[radical] = index\n",
    "\n",
    "n_radical = len(radical_dict)\n",
    "print('the number of radical:', n_radical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset class for image loading and label setting\n",
    "class KanjiRadicalDataset(Dataset):\n",
    "    def __init__(self, image_dir, image_name_list, utf16_to_radical, radical_dict, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_name_list = sorted(image_name_list)\n",
    "        \n",
    "        self.utf16_to_radical = utf16_to_radical\n",
    "        self.radical_dict = radical_dict\n",
    "        \n",
    "        self.n_radical = len(radical_dict)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_name_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_name_list[idx]        \n",
    "        image = Image.open(self.image_dir + image_name)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        label = torch.zeros(self.n_radical)\n",
    "        utf16_code = image_name[:4]\n",
    "        radical_list = self.utf16_to_radical[utf16_code]\n",
    "        for radical in radical_list:\n",
    "            label[radical_dict[radical]] = 1\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of training data: 94127\n",
      "The number of validation data: 23532\n"
     ]
    }
   ],
   "source": [
    "# make dataset and train test split\n",
    "train_name_list, validation_name_list = train_test_split(os.listdir(image_dir), test_size = 0.2, random_state = seed)\n",
    "\n",
    "tf_train = transforms.Compose([transforms.RandomCrop(64, padding=8), transforms.ToTensor()])\n",
    "tf_validation = transforms.ToTensor()\n",
    "\n",
    "train_data = KanjiRadicalDataset(image_dir, train_name_list, utf16_to_radical, radical_dict, transform=tf_train)\n",
    "validation_data = KanjiRadicalDataset(image_dir, validation_name_list, utf16_to_radical, radical_dict, transform=tf_validation)\n",
    "\n",
    "print('The number of training data:', len(train_data))\n",
    "print('The number of validation data:', len(validation_data))\n",
    "\n",
    "# make DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True)\n",
    "validation_loader = DataLoader(validation_data, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのラベルの分布を見る\n",
    "# radical_count = torch.zeros(n_radical)\n",
    "# for index, (image, label) in enumerate(validation_loader):\n",
    "#    radical_count += torch.sum(label, dim=0)\n",
    "#    print('\\rprogress[%d/%d]' % (index+1, len(validation_loader)), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radical_count_non_zero = radical_count[radical_count > 0]\n",
    "# plt.hist(radical_count_non_zero, bins = 30)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(range(len(radical_count_non_zero)), radical_count_non_zero)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kuangliu/pytorch-cifar/blob/master/models/preact_resnet.pyより PreActResNet-18\n",
    "# 本当は多分初期化をちゃんとやったほうが良いが、取り敢えずはこのまま\n",
    "# preactResNet-18の採用理由はkmnistの提案論文のbaselineに合わせるためだが、あれは32x32のkmnist, k49で使われたものなので、\n",
    "# 64x64のkkanjiに適用するのは微妙かも\n",
    "# データセットの提案論文ではmanifold mixupをdata augumentationとして採用していますが、取り敢えずはまだやっていない\n",
    "\n",
    "class PreActBlock(nn.Module):\n",
    "    '''Pre-activation version of the BasicBlock.'''\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(PreActBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(x))\n",
    "        shortcut = self.shortcut(out) if hasattr(self, 'shortcut') else x\n",
    "        out = self.conv1(out)\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        out += shortcut\n",
    "        return out\n",
    "\n",
    "    \n",
    "class PreActResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(PreActResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 8)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "# Todo:情報量ボトルネックがavg_poolの辺りにあるので、ImageNetのPreActResNetとかを参考に改善すること\n",
    "def PreActResNet18(num_classes):\n",
    "    return PreActResNet(PreActBlock, [2,2,2,2], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.nn.functional' has no attribute 'sigmoid_cross_entropy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-8173fdfa7e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.nn.functional' has no attribute 'sigmoid_cross_entropy'"
     ]
    }
   ],
   "source": [
    "criterion = nn.Sigmoid_Cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
